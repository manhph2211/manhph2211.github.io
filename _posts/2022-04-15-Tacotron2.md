---
layout: post
title: Paper Review - Tacontron2
subtitle: Bài 1 TTS
cover-img: /assets/img/path.jpg
# thumbnail-img: /assets/img/thumb.png
share-img: /assets/img/path.jpg
tags: [Speech Synthesis, TTS]
---

# Tổng quan 

Đây là bài đầu tiên trong serie đọc hiểu TTS models của mình:)) Well, bắt đầu với Tacotron 2, với cách tiếp cận Autoregressive thì Tacotron 2 dựa trên recurrent sequence-to-sequence feature prediction network để map character embeddings với mel spectrograms. Sau đó thay vì những thông tin như linguistic, duration, and F0 features, thì predicted mel spectrograms sẽ được đưa qua một bản modified của Wavenet - Vocoder sẽ tổng hợp âm thanh dạng waveforms. Việc consider dùng Mel spec là đúng đắn vì bài báo đã chứng minh được tính hiệu quả của nó cũng như giảm thiểu độ phức tạp cho kích thước Wavenet!

Nhắc lại về Tacotron cũ, một end-to-end generative text-to-speech model, cũng lấy đầu vào từ character sequence và outputs ra corresponding spectrograms. Backbone chính ở Tacotron là seq2seq model with attention. Nhìn hình dưới ta thấy cơ bản thì Tacotron bao gồm một encoder, một attention-based decoder, và một post-processing net. Về phần vocoder thì bài báo đề xuất dùng Griffin-Lim algorithm for phase estimation và tiếp đó sẽ sử dụng inverse short-time Fourier transform. Tuy nhiên, đúng là việc tiếp cận vocoder thế này mang lại sự nghi ngờ LOL. Nó thực sự produces lower audio ﬁdelity and characteristic artifacts when compared to approaches like WaveNet. Ngoài ra, một số các thành phần từ đơn giản đến phức tạp trong Tacotron không thực sự mang lại hiệu quả cao. Sau phần tổng quan mình sẽ note lại những ý chính trong Tacotron 2, cho thấy sự khác biệt với bản old version này!
